{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm as tqdm\n",
    "from IPython.core.display import display\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "cust_demand = pd.read_csv('data/customer_demand.csv')\n",
    "sku_wt_vol = pd.read_csv('data/sku_weight_volume.csv')\n",
    "fixed_cost = pd.read_csv('data/fixed_cost.csv')\n",
    "var_cost = pd.read_csv('data/variable_cost.csv')\n",
    "capacity = pd.read_csv('data/capacity.csv')\n",
    "site_loc = pd.read_csv('data/site_lat_long.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract customer and dc locations\n",
    "## customer location\n",
    "cust_loc = site_loc[site_loc['site'].str.startswith('C')] # extract data with string starting 'C'\n",
    "cust_loc.reset_index() # reset index\n",
    "cust_loc.to_csv('extracted_data/1_cust_loc.csv', index=False) # extract csv file\n",
    "\n",
    "## dc location\n",
    "dc_loc = site_loc[site_loc['site'].str.startswith('DC')] # extract data with string starting 'DC'\n",
    "dc_loc.reset_index() # reset index\n",
    "dc_loc.to_csv('extracted_data/2_dc_loc.csv', index=False) # extract csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "since = time.time()\n",
    "# calculate the unit_transportation cost\n",
    "## calculate sqrt(wt_times_vol) / 20060 (group_num 6*10 + 20,000) and let's call it multiplication_factor_01(mf_01).\n",
    "sku_wt_vol['mf_01'] = np.sqrt(sku_wt_vol['weight'] * sku_wt_vol['volume']) / 20060\n",
    "sku_wt_vol.to_csv('extracted_data/31_sku_wt_vol_mf01.csv') # extract csv file\n",
    "\n",
    "\n",
    "## calculate sqrt((ùëôùëéùë°ùëñ ‚àí ùëôùëéùë°ùëó)2 + (ùëôùëúùëõùëîùëñ ‚àí ùëôùëúùëõùëîùëó)2) and call it multiplication_factor_02 (mf_02)\n",
    "### use cust and dc location datasets\n",
    "### convert pandas dataframe to numpy array\n",
    "### Iterate over data and save enteries in list as extracted data\n",
    "### finally convert list in dictionary, then pandas dataframe and save it as csv file\n",
    "dc_loc_arr = dc_loc.values\n",
    "cust_loc_arr = cust_loc.values\n",
    "dc = []\n",
    "cust = []\n",
    "mf_02 = []\n",
    "for i in range (len(dc_loc_arr)):\n",
    "    for j in range(len(cust_loc_arr)):\n",
    "        dc.append(dc_loc_arr[i][0])\n",
    "        cust.append(cust_loc_arr[j][0])\n",
    "        mf02_calc = np.sqrt(((dc_loc_arr[i][1] - cust_loc_arr[j][1])**2) + ((dc_loc_arr[i][2] - cust_loc_arr[j][2])**2))\n",
    "        mf_02.append(mf02_calc)\n",
    "\n",
    "dc_cust_mf02 = {'dc': dc, 'cust': cust, 'mf_02': mf_02}\n",
    "dc_cust_mf02 = pd.DataFrame(dc_cust_mf02)\n",
    "dc_cust_mf02.to_csv('extracted_data/32_dc_cust_mf02.csv') # extract csv file\n",
    "\n",
    "\n",
    "## link dc_cust_sku dataframes\n",
    "### convert those to arr \n",
    "### iterate sku array over dc and cust arrays and save enteries in list as extracted data\n",
    "### finally conver list in dictionary, then pandas dataframe but don't export it - too big to export csv.\n",
    "dc_cust_mf02_arr = dc_cust_mf02.values\n",
    "sku_wt_vol_arr = sku_wt_vol.values\n",
    "dc = []\n",
    "cust = []\n",
    "sku = []\n",
    "unit_trans_cost = []\n",
    "for i in range(len(dc_cust_mf02_arr)):\n",
    "    for j in range (len(sku_wt_vol_arr)):\n",
    "        dc.append(dc_cust_mf02_arr[i][0])\n",
    "        cust.append(dc_cust_mf02_arr[i][1])\n",
    "        sku.append(sku_wt_vol_arr[j][0])\n",
    "        unit_trans_cost_calc = dc_cust_mf02_arr[i][2] * sku_wt_vol_arr[j][4]\n",
    "        unit_trans_cost.append(unit_trans_cost_calc)\n",
    "dc_cust_sku_unit_trans_cost = {'dc': dc, 'cust': cust, 'sku': sku, 'unit_trans_cost': unit_trans_cost}\n",
    "dc_cust_sku_unit_trans_cost = pd.DataFrame(dc_cust_sku_unit_trans_cost)\n",
    "dc_cust_sku_unit_trans_cost.head()\n",
    "\n",
    "# extract the minimum unit transportation cost\n",
    "dc_cust_sku_unit_trans_cost_grpd = dc_cust_sku_unit_trans_cost.groupby(['cust', 'sku'])['unit_trans_cost'].min() # group data by cust and skus, and find minimum unit transportation cost based on cust and sku\n",
    "dc_cust_sku_unit_trans_cost_idx = dc_cust_sku_unit_trans_cost.set_index(['cust', 'sku']) # set index on original dataframe\n",
    "dc_cust_sku_min_unit_trans_cost = pd.merge(dc_cust_sku_unit_trans_cost_grpd, dc_cust_sku_unit_trans_cost_idx, on=['cust', 'sku', 'unit_trans_cost'], how='left') # merge grouped and indexed dataframes\n",
    "print('check null values in dc_cust_sku_min_unit_trans_cost')\n",
    "print(pd.isna(dc_cust_sku_min_unit_trans_cost).sum()) # check whether there are any null values in extracted dataframe\n",
    "dc_cust_sku_min_unit_trans_cost.to_csv('extracted_data/33_dc_cust_sku_min_unit_trans_cost.csv') # extract csv file\n",
    "\n",
    "\n",
    "# Merge customer demand with unit price calculations to calculate transportation cost\n",
    "cust_demand.rename(columns={'customer': 'cust', 'product': 'sku'}, inplace=True) # rename columns to match with other dataframe to merge easily\n",
    "cust_demand_idx = cust_demand.set_index(['cust', 'sku']) # set index\n",
    "dc_cust_total_transport_cost = pd.merge(cust_demand_idx, dc_cust_sku_min_unit_trans_cost, on=['cust', 'sku'], how='left') # merge dataframes\n",
    "dc_cust_total_transport_cost.reset_index(['cust', 'sku'], inplace=True) # resetting indices\n",
    "dc_cust_total_transport_cost['total_trans_cost'] = dc_cust_total_transport_cost['quantity'] * dc_cust_total_transport_cost['unit_trans_cost'] # calculate transportation cost\n",
    "dc_cust_total_transport_cost[['dc', 'cust', 'sku', 'quantity', 'unit_trans_cost', 'total_trans_cost']] # re-arrange column sequence\n",
    "dc_cust_total_transport_cost.dropna(inplace=True) # drop any null values\n",
    "print('check null values in dc_cust_total_transportation_cost')\n",
    "print(pd.isna(dc_cust_total_transport_cost).sum()) # check whether there are any null values in extracted dataframe\n",
    "print('Shape of dataframe - dc_cust_total_transportation_cost:', dc_cust_total_transport_cost.shape)\n",
    "dc_cust_total_transport_cost.to_csv('extracted_data/34_dc_cust_total_transport_cost.csv') # extract csv file\n",
    "\n",
    "\n",
    "# throughput of each dc\n",
    "dc_total_throughput = dc_cust_total_transport_cost.groupby('dc')['quantity'].sum() # add total quantity for each dc\n",
    "dc_total_throughput = pd.DataFrame(dc_total_throughput) # convert to dataframe\n",
    "dc_total_throughput.to_csv('extracted_data/35_dc_total_throughput.csv') # extract csv file\n",
    "\n",
    "\n",
    "# total transportation cost for each dc\n",
    "dc_total_transport_cost = dc_cust_total_transport_cost.groupby('dc')['total_trans_cost'].sum() # add total transporation cost for each dc\n",
    "dc_total_transport_cost = pd.DataFrame(dc_total_transport_cost) # convert to dataframe\n",
    "dc_total_transport_cost.to_csv('extracted_data/36_dc_total_transport_cost.csv') # extract csv file\n",
    "\n",
    "\n",
    "# total variable cost for each dc\n",
    "var_cost_idx = var_cost.set_index('dc') # set index \n",
    "dc_total_var_cost = var_cost_idx.join(dc_total_throughput) # merge variable cost with througput of each dc \n",
    "dc_total_var_cost['total_var_cost'] = dc_total_var_cost['variable_cost'] * dc_total_var_cost['quantity'] # calculate total variable cost based on unit varible cost * total quantity\n",
    "dc_total_var_cost.drop(columns='quantity', inplace=True) # drop quantity column\n",
    "dc_total_var_cost.to_csv('extracted_data/37_dc_total_var_cost.csv') # extract csv file\n",
    "\n",
    "# total network cost for each dc\n",
    "## summarising the table with all cost values and throughput\n",
    "fixed_cost_idx = fixed_cost.set_index('dc') # set index \n",
    "dc_total_network_cost = fixed_cost_idx.join(dc_total_var_cost) # merge fixed and variable costs\n",
    "dc_total_network_cost = dc_total_network_cost.join(dc_total_transport_cost) # merging transportation costs\n",
    "dc_total_network_cost.to_csv('extracted_data/38_dc_total_network_cost.csv') # extract csv file\n",
    "print(f'Time taken: {float((time.time() - since)/60): 0.2f} in minutes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "since = time.time()\n",
    "# merge customer demand dataframe with sku dataframe and then on dc_cust_locations\n",
    "cust_demand_idx = cust_demand.set_index('sku')\n",
    "sku_wt_vol_idx = sku_wt_vol.set_index('sku')\n",
    "x = pd.merge(cust_demand_idx, sku_wt_vol_idx, on='sku', how = 'left')  # merging 2 dataframes\n",
    "x.dropna(inplace=True) # remove null values\n",
    "x.reset_index(inplace=True) # resetting index\n",
    "x.set_index('cust', inplace=True) # setting index\n",
    "dc_cust_sku_to_bin = pd.merge(x, dc_cust_mf02, on='cust', how = 'left')  # merging 2 dataframes\n",
    "dc_cust_sku_to_bin = dc_cust_sku_to_bin[['dc', 'cust', 'sku', 'quantity', 'weight', 'volume', 'mf_01', 'mf_02']]\n",
    "print('check null values in dc_cust_sku_to_bin')\n",
    "print(pd.isna(dc_cust_sku_to_bin).sum())\n",
    "\n",
    "# Bin customer demand dataframe in 120 groups\n",
    "filter1 = dc_cust_sku_to_bin['quantity']<=10\n",
    "filter2 = (dc_cust_sku_to_bin['quantity']>10) & (dc_cust_sku_to_bin['quantity']<=60)\n",
    "filter3 = (dc_cust_sku_to_bin['quantity']>60) & (dc_cust_sku_to_bin['quantity']<=200)\n",
    "filter4 = (dc_cust_sku_to_bin['quantity']>200) & (dc_cust_sku_to_bin['quantity']<=1000)\n",
    "filter5 = (dc_cust_sku_to_bin['quantity']>1000) & (dc_cust_sku_to_bin['quantity']<=5000)\n",
    "filter6 = (dc_cust_sku_to_bin['quantity']>5000) & (dc_cust_sku_to_bin['quantity']<=10000)\n",
    "filter7 = dc_cust_sku_to_bin['quantity']>10000\n",
    "\n",
    "labels1 = np.arange(1,11)\n",
    "labels2 = np.arange(11,21)\n",
    "labels3 = np.arange(21,31)\n",
    "labels4 = np.arange(31,81)\n",
    "labels5 = np.arange(81,106)\n",
    "labels6 = np.arange(106,116)\n",
    "labels7 = np.arange(116,121)\n",
    "\n",
    "x1 = dc_cust_sku_to_bin[filter1]\n",
    "x2 = dc_cust_sku_to_bin[filter2]\n",
    "x3 = dc_cust_sku_to_bin[filter3]\n",
    "x4 = dc_cust_sku_to_bin[filter4]\n",
    "x5 = dc_cust_sku_to_bin[filter5]\n",
    "x6 = dc_cust_sku_to_bin[filter6]\n",
    "x7 = dc_cust_sku_to_bin[filter7]\n",
    "\n",
    "x1['bin_id'] = pd.cut(x1['quantity'], bins=10, labels=labels1)\n",
    "x2['bin_id'] = pd.cut(x2['quantity'], bins=10, labels=labels2)\n",
    "x3['bin_id'] = pd.cut(x3['quantity'], bins=10, labels=labels3)\n",
    "x4['bin_id'] = pd.cut(x4['quantity'], bins=50, labels=labels4)\n",
    "x5['bin_id'] = pd.cut(x5['quantity'], bins=25, labels=labels5)\n",
    "x6['bin_id'] = pd.cut(x6['quantity'], bins=10, labels=labels6)\n",
    "x7['bin_id'] = pd.cut(x7['quantity'], bins=5, labels=labels7)\n",
    "\n",
    "print(f'Unique bin counts of quantity <=10 : ', len(x1['bin_id'].unique()))\n",
    "print(f'Unique bin counts of quantity > 10 but <= 60 : ', len(x2['bin_id'].unique()))\n",
    "print(f'Unique bin counts of quantity > 60 but <= 20dc_cust_sku_binned0 : ', len(x3['bin_id'].unique()))\n",
    "print(f'Unique bin counts of quantity > 200 but <= 1000 : ', len(x4['bin_id'].unique()))\n",
    "print(f'Unique bin counts of quantity > 1000 but <= 5000 : ', len(x5['bin_id'].unique()))\n",
    "print(f'Unique bin counts of quantity > 5000 but <= 10000 : ', len(x6['bin_id'].unique()))\n",
    "print(f'Unique bin counts of quantity > 10000: ', len(x7['bin_id'].unique()))\n",
    "\n",
    "# merge all these splitted dataframes to make a new dataframe - dc_cust_sku_binned\n",
    "x = [x1, x2, x3, x4, x5, x6, x7]\n",
    "dc_cust_sku_binned = pd.concat(x)\n",
    "print('Shape of new dc_cust_sku_binned dataframe: ', dc_cust_sku_binned.shape)\n",
    "print(f'Unique bin counts of quantity in new dc_cust_sku_binned dataframe: ', len(dc_cust_sku_binned['bin_id'].unique()))\n",
    "\n",
    "\n",
    "# finding square root(average weight times volume) based on bins\n",
    "dc_cust_sku_binned['mf_01'] = dc_cust_sku_binned['weight'] * dc_cust_sku_binned['volume'] # weight times volume\n",
    "average_wt_volume = dc_cust_sku_binned.groupby('bin_id')['mf_01'].mean() # average of weight times volume based on bin_id\n",
    "average_wt_volume = pd.DataFrame(average_wt_volume) # create dataframe\n",
    "dc_cust_sku_binned.set_index('bin_id', inplace=True) # set index\n",
    "dc_cust_sku_binned = pd.merge(dc_cust_sku_binned, average_wt_volume, on='bin_id', how='left') # merge dataframes\n",
    "dc_cust_sku_binned.rename(columns={'mf_01_x': 'weight_volume', 'mf_01_y': 'avr_weight_volume'}, inplace=True) # rename columns\n",
    "dc_cust_sku_binned['mf_01'] = np.sqrt(dc_cust_sku_binned['avr_weight_volume']) / 20060 # find the square root(wt*vol) /20060\n",
    "\n",
    "\n",
    "# finding minimum unit transportation cost\n",
    "dc_cust_sku_binned['unit_trans_cost'] = dc_cust_sku_binned['mf_01'] * dc_cust_sku_binned['mf_02']\n",
    "dc_cust_sku_unit_trans_cost = dc_cust_sku_binned.groupby(['cust', 'sku'])['unit_trans_cost'].min()\n",
    "\n",
    "\n",
    "# calculating total transportation cost for each product for each customer\n",
    "dc_cust_sku_unit_trans_cost = pd.DataFrame(dc_cust_sku_unit_trans_cost)\n",
    "dc_cust_sku_total_trans_cost = pd.merge(dc_cust_sku_unit_trans_cost, dc_cust_sku_binned, on=['cust', 'sku', 'unit_trans_cost'], how='left')\n",
    "dc_cust_sku_total_trans_cost.dropna(inplace=True)\n",
    "dc_cust_sku_total_trans_cost = dc_cust_sku_total_trans_cost[['dc', 'cust', 'sku', 'quantity', 'weight', 'volume', 'avr_weight_volume' , 'unit_trans_cost']]\n",
    "dc_cust_sku_total_trans_cost['total_trans_cost'] = dc_cust_sku_total_trans_cost['quantity'] * dc_cust_sku_total_trans_cost['unit_trans_cost']\n",
    "dc_cust_sku_total_trans_cost.to_csv('extracted_data/41_dc_cust_sku_total_trans_cost.csv') # extract csv file\n",
    "\n",
    "\n",
    "# throughput of each dc\n",
    "dc_total_throughput = dc_cust_sku_total_trans_cost.groupby('dc')['quantity'].sum() # add total quantity for each dc\n",
    "dc_total_throughput = pd.DataFrame(dc_total_throughput) # convert to dataframe\n",
    "dc_total_throughput.to_csv('extracted_data/42_dc_total_throughput.csv') # extract csv file\n",
    "\n",
    "\n",
    "# total transportation cost for each dc\n",
    "dc_total_transport_cost = dc_cust_sku_total_trans_cost.groupby('dc')['total_trans_cost'].sum() # add total transporation cost for each dc\n",
    "dc_total_transport_cost = pd.DataFrame(dc_total_transport_cost) # convert to dataframe\n",
    "dc_total_transport_cost.to_csv('extracted_data/43_dc_total_transport_cost.csv') # extract csv file\n",
    "\n",
    "\n",
    "# total variable cost for each dc\n",
    "var_cost_idx = var_cost.set_index('dc') # set index \n",
    "dc_total_var_cost = var_cost_idx.join(dc_total_throughput) # merge variable cost with througput of each dc \n",
    "dc_total_var_cost['total_var_cost'] = dc_total_var_cost['variable_cost'] * dc_total_var_cost['quantity'] # calculate total variable cost based on unit varible cost * total quantity\n",
    "dc_total_var_cost.drop(columns='quantity', inplace=True) # drop quantity column\n",
    "dc_total_var_cost.to_csv('extracted_data/44_dc_total_var_cost.csv') # extract csv file\n",
    "\n",
    "# total network cost for each dc\n",
    "## summarising the table with all cost values and throughput\n",
    "fixed_cost_idx = fixed_cost.set_index('dc') # set index \n",
    "dc_total_network_cost = fixed_cost_idx.join(dc_total_var_cost) # merge fixed and variable costs\n",
    "dc_total_network_cost = dc_total_network_cost.join(dc_total_transport_cost) # merging transportation costs\n",
    "dc_total_network_cost.to_csv('extracted_data/45_dc_total_network_cost.csv') # extract csv file\n",
    "print(f'Time taken: {float((time.time() - since)/60): 0.2f} in minutes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "since = time.time()\n",
    "# merge customer demand dataframe with sku dataframe and then on dc_cust_locations\n",
    "cust_demand_idx = cust_demand.set_index('sku')\n",
    "sku_wt_vol_idx = sku_wt_vol.set_index('sku')\n",
    "x = pd.merge(cust_demand_idx, sku_wt_vol_idx, on='sku', how = 'left')  # merging 2 dataframes\n",
    "x.dropna(inplace=True) # remove null values\n",
    "x.reset_index(inplace=True) # resetting index\n",
    "x.set_index('cust', inplace=True) # setting index\n",
    "dc_cust_sku_to_bin = pd.merge(x, dc_cust_mf02, on='cust', how = 'left')  # merging 2 dataframes\n",
    "dc_cust_sku_to_bin = dc_cust_sku_to_bin[['dc', 'cust', 'sku', 'quantity', 'weight', 'volume', 'mf_01', 'mf_02']]\n",
    "print('check null values in dc_cust_sku_to_bin')\n",
    "print(pd.isna(dc_cust_sku_to_bin).sum())\n",
    "\n",
    "# Bin customer demand dataframe in 120 groups\n",
    "filter1 = dc_cust_sku_to_bin['quantity']<=10000\n",
    "filter2 = dc_cust_sku_to_bin['quantity']>10000\n",
    "\n",
    "labels1 = np.arange(1,11)\n",
    "labels2 = np.arange(11,13)\n",
    "\n",
    "x1 = dc_cust_sku_to_bin[filter1]\n",
    "x2 = dc_cust_sku_to_bin[filter2]\n",
    "\n",
    "x1['bin_id'] = pd.cut(x1['quantity'], bins=10, labels=labels1)\n",
    "x2['bin_id'] = pd.cut(x2['quantity'], bins=2, labels=labels2)\n",
    "\n",
    "print(f'Unique bin counts of quantity <=10000 : ', len(x1['bin_id'].unique()))\n",
    "print(f'Unique bin counts of quantity > 10000: ', len(x2['bin_id'].unique()))\n",
    "\n",
    "# merge all these splitted dataframes to make a new dataframe - dc_cust_sku_binned\n",
    "x = [x1, x2]\n",
    "dc_cust_sku_binned = pd.concat(x)\n",
    "print('Shape of new dc_cust_sku_binned dataframe: ', dc_cust_sku_binned.shape)\n",
    "print(f'Unique bin counts of quantity in new dc_cust_sku_binned dataframe: ', len(dc_cust_sku_binned['bin_id'].unique()))\n",
    "\n",
    "\n",
    "# finding square root(average weight times volume) based on bins\n",
    "dc_cust_sku_binned['mf_01'] = dc_cust_sku_binned['weight'] * dc_cust_sku_binned['volume'] # weight times volume\n",
    "average_wt_volume = dc_cust_sku_binned.groupby('bin_id')['mf_01'].mean() # average of weight times volume based on bin_id\n",
    "average_wt_volume = pd.DataFrame(average_wt_volume) # create dataframe\n",
    "dc_cust_sku_binned.set_index('bin_id', inplace=True) # set index\n",
    "dc_cust_sku_binned = pd.merge(dc_cust_sku_binned, average_wt_volume, on='bin_id', how='left') # merge dataframes\n",
    "dc_cust_sku_binned.rename(columns={'mf_01_x': 'weight_volume', 'mf_01_y': 'avr_weight_volume'}, inplace=True) # rename columns\n",
    "dc_cust_sku_binned['mf_01'] = np.sqrt(dc_cust_sku_binned['avr_weight_volume']) / 20060 # find the square root(wt*vol) /20060\n",
    "\n",
    "\n",
    "# finding minimum unit transportation cost\n",
    "dc_cust_sku_binned['unit_trans_cost'] = dc_cust_sku_binned['mf_01'] * dc_cust_sku_binned['mf_02']\n",
    "dc_cust_sku_unit_trans_cost = dc_cust_sku_binned.groupby(['cust', 'sku'])['unit_trans_cost'].min()\n",
    "\n",
    "\n",
    "# calculating total transportation cost for each product for each customer\n",
    "dc_cust_sku_unit_trans_cost = pd.DataFrame(dc_cust_sku_unit_trans_cost)\n",
    "dc_cust_sku_total_trans_cost = pd.merge(dc_cust_sku_unit_trans_cost, dc_cust_sku_binned, on=['cust', 'sku', 'unit_trans_cost'], how='left')\n",
    "dc_cust_sku_total_trans_cost.dropna(inplace=True)\n",
    "dc_cust_sku_total_trans_cost = dc_cust_sku_total_trans_cost[['dc', 'cust', 'sku', 'quantity', 'weight', 'volume', 'avr_weight_volume' , 'unit_trans_cost']]\n",
    "dc_cust_sku_total_trans_cost['total_trans_cost'] = dc_cust_sku_total_trans_cost['quantity'] * dc_cust_sku_total_trans_cost['unit_trans_cost']\n",
    "dc_cust_sku_total_trans_cost.to_csv('extracted_data/51_dc_cust_sku_total_trans_cost.csv') # extract csv file\n",
    "\n",
    "\n",
    "# throughput of each dc\n",
    "dc_total_throughput = dc_cust_sku_total_trans_cost.groupby('dc')['quantity'].sum() # add total quantity for each dc\n",
    "dc_total_throughput = pd.DataFrame(dc_total_throughput) # convert to dataframe\n",
    "dc_total_throughput.to_csv('extracted_data/52_dc_total_throughput.csv') # extract csv file\n",
    "\n",
    "\n",
    "# total transportation cost for each dc\n",
    "dc_total_transport_cost = dc_cust_sku_total_trans_cost.groupby('dc')['total_trans_cost'].sum() # add total transporation cost for each dc\n",
    "dc_total_transport_cost = pd.DataFrame(dc_total_transport_cost) # convert to dataframe\n",
    "dc_total_transport_cost.to_csv('extracted_data/53_dc_total_transport_cost.csv') # extract csv file\n",
    "\n",
    "\n",
    "# total variable cost for each dc\n",
    "var_cost_idx = var_cost.set_index('dc') # set index \n",
    "dc_total_var_cost = var_cost_idx.join(dc_total_throughput) # merge variable cost with througput of each dc \n",
    "dc_total_var_cost['total_var_cost'] = dc_total_var_cost['variable_cost'] * dc_total_var_cost['quantity'] # calculate total variable cost based on unit varible cost * total quantity\n",
    "dc_total_var_cost.drop(columns='quantity', inplace=True) # drop quantity column\n",
    "dc_total_var_cost.to_csv('extracted_data/54_dc_total_var_cost.csv') # extract csv file\n",
    "\n",
    "# total network cost for each dc\n",
    "## summarising the table with all cost values and throughput\n",
    "fixed_cost_idx = fixed_cost.set_index('dc') # set index \n",
    "dc_total_network_cost = fixed_cost_idx.join(dc_total_var_cost) # merge fixed and variable costs\n",
    "dc_total_network_cost = dc_total_network_cost.join(dc_total_transport_cost) # merging transportation costs\n",
    "dc_total_network_cost.to_csv('extracted_data/55_dc_total_network_cost.csv') # extract csv file\n",
    "print(f'Time taken: {float((time.time() - since)/60): 0.2f} in minutes.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
